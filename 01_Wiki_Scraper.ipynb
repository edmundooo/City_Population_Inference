{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Subject:__      Infering City Population Size from City Data\n",
    "\n",
    "__Date:__         07/20/2018\n",
    "\n",
    "__Name:__         Edmund D. Chitwood\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notebook Summary:__<br> \n",
    "<br>The following Notebook contains functions that \n",
    "-  scrape web pages and turn them to Beautiful Soup, \n",
    "-  iterate over lists of the Wikipedia pages of cities with populations of 100,000 or more, \n",
    "-  parse sections within those Wikipedia pages to extract city data from them, \n",
    "-  add that data into city dictionaries within lists, \n",
    "-  add those lists of dicts to Pandas DataFrames and \n",
    "-  pickle the combined DataFrames. \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "import re\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get response object from URL and turn text element into Beautiful Soup.\n",
    "# Return soup.\n",
    "\n",
    "def web_page_to_soup(url):\n",
    "    response = requests.get(url)\n",
    "    if response == None:\n",
    "        return None\n",
    "    \n",
    "    # Make sure requests return an objext with the correct status code.\n",
    "    if response.status_code != 200:\n",
    "        return None\n",
    "    \n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\") \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use class fn org to target city name.\n",
    "# Return name of city.\n",
    "\n",
    "def city_name_from_soup(soup):\n",
    "    try:\n",
    "        city_name = soup.find(class_='fn org').text\n",
    "    except AttributeError:\n",
    "    \n",
    "    # Except handles instances where there is no fn org class,\n",
    "    # which raises an error since NoneType has no Attribute Text\n",
    "    # (e.g. https://en.wikipedia.org/wiki/Adelaide).\n",
    "        city_name = 'No Name' \n",
    "    \n",
    "    return city_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use class geo to target latitude and longitude. \n",
    "# Return city latitude and longitude. \n",
    "\n",
    "def lat_lon_from_soup(soup):\n",
    "    try:\n",
    "        lat_lon = soup.find(class_='geo').text\n",
    "        lat_lon_list = lat_lon.split(';')\n",
    "        lat = float(lat_lon_list[0])\n",
    "        lon = float(lat_lon_list[1]) \n",
    "    \n",
    "    # Except handles instances where there is no geo class,\n",
    "    # which raises an error since NoneType has no Attribute Text.\n",
    "    # In that case, pass in null values.\n",
    "    except AttributeError:\n",
    "        lat = float('nan')\n",
    "        lon = float('nan')\n",
    "    \n",
    "    return lat,lon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use class infobox geography vcard to target city infobox.\n",
    "# Return area of city in square miles.\n",
    "\n",
    "def area_from_soup(soup):    \n",
    "    try:\n",
    "        infobox_string = (soup.find(attrs={'class' : 'infobox geography vcard'})\n",
    "                              .find(text=re.compile('sq')))\n",
    "        \n",
    "        # Return the normal form of unicode string.\n",
    "        area_string = unicodedata.normalize('NFKD', infobox_string).encode('ascii','ignore')\n",
    "        area_string = str(area_string)\n",
    "        area_list = area_string.split('sq mi')\n",
    "        area_string_sq_mi = area_list[0]\n",
    "        \n",
    "        # Use regex and replace to deal with decimals and commas.\n",
    "        area_list = re.findall(r\"[-+]?\\d*\\,\\d+\\.\\d+|\\d*\\.\\d+|\\d*\\,\\d+|\\d+\", area_string_sq_mi)\n",
    "        area_string_sq_mi = area_list[0]\n",
    "        area_sq_mi = float(area_string_sq_mi.replace(',',''))\n",
    "        \n",
    "        # Check for instances of 'sq' before area in sq units. \n",
    "        area_string = (soup.find(attrs={'class' : 'infobox geography vcard'})\n",
    "                           .find(text=re.compile('sq'))\n",
    "                           .parent\n",
    "                           .parent)\n",
    "        if '/sq' in str(area_string.text):\n",
    "            area_sq_mi = float('nan')\n",
    "\n",
    "    # Except handles instances area numbers are out of order, \n",
    "    # contain unusual syntax, listed in sq km etc.\n",
    "    # In those case, try getting area in sq mi a differnt way.\n",
    "    except (TypeError, IndexError, AttributeError) as e:\n",
    "        try:\n",
    "            sq_list = list(soup.find(attrs={'class' : 'infobox geography vcard'}).findAll(text=re.compile('sq')))\n",
    "            sq_num_list = []\n",
    "            for s in sq_list:\n",
    "                sq_num_list.append(re.findall(r\"[-+]?\\d*\\,\\d+\\.\\d+|\\d*\\.\\d+|\\d*\\,\\d+|\\d+\", s))\n",
    "            \n",
    "            sq_num_floats = []\n",
    "            for s in sq_num_list:\n",
    "                if s == []:\n",
    "                    pass\n",
    "                else:\n",
    "                    sq_num_floats.append(float(s[0].replace(',','')))\n",
    "            \n",
    "            area_sq_mi = sorted(sq_num_floats)[0]\n",
    "        \n",
    "        # Except handles instances area numbers are out of order, \n",
    "        # contain unusual syntax, listed in sq km etc.\n",
    "        # In those case, try getting area in sq mi a differnt way.\n",
    "        except (TypeError, IndexError, AttributeError) as e:\n",
    "            area_sq_mi = float('nan')\n",
    "    \n",
    "    return area_sq_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use class infobox geography vcard to target city infobox.\n",
    "# Return population of city.\n",
    "\n",
    "def population_from_soup(soup):\n",
    "    try:\n",
    "        infobox_string = (soup.find(attrs={'class' : 'infobox geography vcard'})\n",
    "                                .find(text=re.compile('Population'))\n",
    "                                .parent\n",
    "                                .parent\n",
    "                                .findNextSibling()\n",
    "                                .find('td'))\n",
    "        infobox_string_2 = (soup.find(attrs={'class' : 'infobox geography vcard'})\n",
    "                                .find(text=re.compile('Population'))\n",
    "                                .parent\n",
    "                                .parent\n",
    "                                .findNextSibling()\n",
    "                                .find('td')\n",
    "                                .find(text=re.compile('Population')))\n",
    "        \n",
    "        # The following if statements handle atypical population data content\n",
    "        # and formatting. For example, some infoboxes contain population \n",
    "        # figures for cities in multiple contexts (e.g. municipality, metro region).\n",
    "        if infobox_string_2 == None:\n",
    "            infobox_string = (soup.find(attrs={'class' : 'infobox geography vcard'})\n",
    "                                  .find(text=re.compile('Population'))\n",
    "                                  .parent\n",
    "                                  .parent\n",
    "                                  .find('td'))\n",
    "            if infobox_string == None:\n",
    "                infobox_string = (soup.find(attrs={'class' : 'infobox geography vcard'})\n",
    "                                      .find(text=re.compile('Population'))\n",
    "                                      .parent\n",
    "                                      .parent\n",
    "                                      .findNextSibling()\n",
    "                                      .find('td'))\n",
    "                \n",
    "            if 'sq' in str(infobox_string.text):\n",
    "                infobox_string = (soup.find(attrs={'class' : 'infobox geography vcard'})\n",
    "                                      .find(text=re.compile('Population'))\n",
    "                                      .parent\n",
    "                                      .parent\n",
    "                                      .findNextSibling()\n",
    "                                      .findNextSibling()\n",
    "                                      .find('td'))\n",
    "                \n",
    "        pop_string = str(infobox_string.text)\n",
    "        pop_string = pop_string.split('[')[0]\n",
    "        pop_string = pop_string.split('(')[0]\n",
    "        pop_string = ''.join(e for e in pop_string if e.isdigit())            \n",
    "        population = int(pop_string)\n",
    "    \n",
    "    # Except handles instances where population is not organized within\n",
    "    # td element (e.g. https://en.wikipedia.org/wiki/Adelaide).\n",
    "    # In those case, pass in null values.\n",
    "    except (AttributeError, ValueError) as e:\n",
    "        population = float('nan')\n",
    "        \n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use class infobox geography vcard to target city infobox.\n",
    "# Return elevation above sea level in feet.\n",
    "\n",
    "def elevation_from_soup(soup):\n",
    "    try:\n",
    "        infobox_string = (soup.find(attrs={'class' : 'infobox geography vcard'})\n",
    "                              .find(text=re.compile('Elevation'))\n",
    "                              .parent\n",
    "                              .parent\n",
    "                              .find('td')\n",
    "                              .text)\n",
    "        elevation_list = infobox_string.split('(')\n",
    "        \n",
    "        # Use regex and replace to deal with decimals and commas.\n",
    "        elevation_list_1 = re.findall(r\"[-+]?\\d*\\,\\d+\\.\\d+|\\d*\\.\\d+|\\d*\\,\\d+|\\d+\", elevation_list[0])\n",
    "        elevation_list_2 = re.findall(r\"[-+]?\\d*\\,\\d+\\.\\d+|\\d*\\.\\d+|\\d*\\,\\d+|\\d+\", elevation_list[1])\n",
    "        elevation_1 = float(elevation_list_1[-1].replace(',',''))\n",
    "        elevation_2 = float(elevation_list_2[-1].replace(',',''))\n",
    "        \n",
    "        # Make sure elevation returns in feet rather than meters.\n",
    "        if elevation_1 > elevation_2:\n",
    "            elevation = elevation_1\n",
    "        else:\n",
    "            elevation = elevation_2\n",
    "            \n",
    "    except (AttributeError, IndexError) as e:\n",
    "            try:\n",
    "                infobox_string = (soup.find(attrs={'class' : 'infobox geography vcard'})\n",
    "                                      .find(text=re.compile('Highest'))\n",
    "                                      .parent\n",
    "                                      .parent\n",
    "                                      .find('td')\n",
    "                                      .text)\n",
    "                elevation_list = infobox_string.split('(')\n",
    "                elevation_list_1 = re.findall(r\"[-+]?\\d*\\,\\d+\\.\\d+|\\d*\\.\\d+|\\d*\\,\\d+|\\d+\", elevation_list[0])\n",
    "                elevation_list_2 = re.findall(r\"[-+]?\\d*\\,\\d+\\.\\d+|\\d*\\.\\d+|\\d*\\,\\d+|\\d+\", elevation_list[1])\n",
    "                elevation_1 = float(elevation_list_1[-1].replace(',',''))\n",
    "                elevation_2 = float(elevation_list_2[-1].replace(',',''))\n",
    "\n",
    "                if elevation_1 > elevation_2:\n",
    "                    elevation = elevation_1\n",
    "                else:\n",
    "                    elevation = elevation_2\n",
    "                    \n",
    "            except (AttributeError, IndexError) as e:\n",
    "                \n",
    "                # Handle cases where elevation listed at top of climate table,\n",
    "                # as is the case of the city A Coruna.\n",
    "                try:\n",
    "                    infobox_string = (soup.find(attrs={'class' : 'wikitable collapsible'})\n",
    "                                          .find('th')\n",
    "                                          .text)\n",
    "                    elevation_list = infobox_string.split(' ')\n",
    "                    feet_string = None\n",
    "                    for s in elevation_list:\n",
    "                        if 'feet' in s:\n",
    "                            feet_string = s\n",
    "                            \n",
    "                    if feet_string == None:\n",
    "                        elevation = float('nan')\n",
    "                        return elevation\n",
    "                    \n",
    "                    position = elevation_list.index(feet_string)\n",
    "                    elevation_string = elevation_list[position-1]\n",
    "                    elevation = float(elevation_string.replace('(',''))\n",
    "                except (AttributeError, IndexError) as e:\n",
    "                    elevation = float('nan')\n",
    "    \n",
    "    return elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use class wikitable collapsible or wikitable collapsible collpsed to target city climate table.\n",
    "# Return climate table in climate object. This includes the data points targeted by the next five functions.\n",
    "# Some city pages (e.g. Amadora) have no climate table at all.\n",
    "\n",
    "def climate_from_soup(soup):\n",
    "    climate = soup.find(attrs={'class' : 'wikitable collapsible'})\n",
    "    \n",
    "    # For a city like Shenzen, the climate table is collpsed, the following if statement handles such cases.\n",
    "    if climate == None:\n",
    "        climate = soup.find(attrs={'class' : 'wikitable collapsible collapsed'})\n",
    "    \n",
    "    return climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use find to target temp in the climate object.\n",
    "# Return temp in fahrenheit.\n",
    "\n",
    "def average_high_temp_from_climate(climate):\n",
    "    try:\n",
    "        temp_result_set = (climate.find(text=re.compile('Average high'))\n",
    "                                  .parent\n",
    "                                  .parent\n",
    "                                  .findAll('td'))\n",
    "        \n",
    "        # Annual values are listed in the last columns of the climate tables.\n",
    "        temp_string = temp_result_set[-1].text\n",
    "        temp_list = temp_string.split('(')\n",
    "\n",
    "        # Get temp in celsius and fahrenheit.\n",
    "        # Use regex to deal with decimals.\n",
    "        temp_list_1 = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", temp_list[0])\n",
    "        temp_list_2 = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", temp_list[1])\n",
    "        temp_float_1 = float(temp_list_1[0])\n",
    "        temp_float_2 = float(temp_list_2[0])\n",
    "\n",
    "        # Compare temps and return the one in fahrenheit (i.e. the larger number).\n",
    "        if temp_float_1 > temp_float_2:\n",
    "            temp_float = temp_float_1\n",
    "        else:\n",
    "            temp_float = temp_float_2\n",
    "            \n",
    "    except (AttributeError, IndexError) as e:\n",
    "        temp_float = float('nan')\n",
    "        \n",
    "    return temp_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use find to target temp in the climate object.\n",
    "# Return temp in fahrenheit.\n",
    "\n",
    "def average_low_temp_from_climate(climate):\n",
    "    try:\n",
    "        temp_result_set = (climate.find(text=re.compile('Average low'))\n",
    "                                  .parent\n",
    "                                  .parent\n",
    "                                  .findAll('td'))\n",
    "        \n",
    "        # Annual values are listed in the last columns of the climate tables.\n",
    "        temp_string = temp_result_set[-1].text\n",
    "        temp_list = temp_string.split('(')\n",
    "\n",
    "        # Get temp in celsius and fahrenheit.\n",
    "        # Use regex to deal with decimals.\n",
    "        temp_list_1 = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", temp_list[0])\n",
    "        temp_list_2 = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", temp_list[1])        \n",
    "        temp_float_1 = float(temp_list_1[0])\n",
    "        temp_float_2 = float(temp_list_2[0])\n",
    "\n",
    "        # Compare temps and return fahrenheit (i.e. the larger number).\n",
    "        if temp_float_1 > temp_float_2:\n",
    "            temp_float = temp_float_1\n",
    "        else:\n",
    "            temp_float = temp_float_2\n",
    "    \n",
    "    except (AttributeError, IndexError) as e:\n",
    "        temp_float = float('nan')\n",
    "        \n",
    "    return temp_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use find to target average precipitation days in the climate object.\n",
    "# Return annual rainy days.\n",
    "\n",
    "def annual_precipitation_days_from_climate(climate):\n",
    "    \n",
    "    # In some climate tables, average precipitation days are refered to as Average Rainy Days.\n",
    "    try:\n",
    "        average_precipition_days_result_set = (climate.find(text=re.compile('Average rainy days'))\n",
    "                                                      .parent\n",
    "                                                      .parent\n",
    "                                                      .findAll('td'))\n",
    "        \n",
    "        # Annual values are listed in the last columns of the climate tables.\n",
    "        precipitation_string = average_precipition_days_result_set[-1].text\n",
    "        precipitation_string = precipitation_string.strip('\\n')\n",
    "        precipitation_days = float(precipitation_string)\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            average_precipition_days_result_set = (climate.find(text=re.compile('Average precipitation days'))\n",
    "                                                          .parent\n",
    "                                                          .parent\n",
    "                                                          .findAll('td'))\n",
    "            precipitation_string = average_precipition_days_result_set[-1].text.strip('\\n')\n",
    "            precipitation_days = float(precipitation_string)\n",
    "        except AttributeError:\n",
    "            precipitation_days = float('nan')\n",
    "\n",
    "    return precipitation_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use find to target average precipitation inches in the climate object.\n",
    "# Return annual precipitation in inches.\n",
    "\n",
    "def annual_precipitation_inches_from_climate(climate):   \n",
    "    try:\n",
    "        average_precipition_measurements_result_set = (climate.find(text=re.compile('precipitation'))\n",
    "                                                              .parent\n",
    "                                                              .parent\n",
    "                                                              .parent\n",
    "                                                              .findAll('td'))\n",
    "    except (AttributeError, IndexError) as e:\n",
    "        try:\n",
    "            average_precipition_measurements_result_set = (climate.find(text=re.compile('Average rainfall'))\n",
    "                                                                  .parent\n",
    "                                                                  .parent\n",
    "                                                                  .findAll('td'))\n",
    "        except (AttributeError, IndexError) as e:\n",
    "            return float('nan')\n",
    "\n",
    "    try:\n",
    "        \n",
    "        # Annual values are listed in the last columns of the climate tables.\n",
    "        precipitation_measurements_string = average_precipition_measurements_result_set[-1].text\n",
    "        precipitation_measurements_list = precipitation_measurements_string.split(' ')\n",
    "\n",
    "        # Get precipitation in cm and in.\n",
    "        # Use regex and replace to deal with decimals and commas.\n",
    "        precipitation_1 = re.findall(r\"[-+]?\\d*\\,\\d+\\.\\d+|\\d*\\.\\d+|\\d*\\,\\d+|\\d+\", precipitation_measurements_list[0])\n",
    "        precipitation_2 = re.findall(r\"[-+]?\\d*\\,\\d+\\.\\d+|\\d*\\.\\d+|\\d*\\,\\d+|\\d+\", precipitation_measurements_list[1])\n",
    "        precipitation_1 = float(precipitation_1[0].replace(',',''))\n",
    "        precipitation_2 = float(precipitation_2[0].replace(',',''))\n",
    "\n",
    "        # Compare temps and return inches (i.e. the smaller number).\n",
    "        if precipitation_1 > precipitation_2:\n",
    "            precipitation_inches = precipitation_2\n",
    "        else:\n",
    "            precipitation_inches = precipitation_1\n",
    "    except (AttributeError, IndexError) as e:\n",
    "        precipitation_inches = float('nan')\n",
    "\n",
    "    return precipitation_inches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use find to target annual sunshine hours in the climate object.\n",
    "# Return annual sunshine hours.\n",
    "\n",
    "def annual_sunshine_hours_from_climate(climate):\n",
    "    try:\n",
    "        annual_sunshine_result_set = (climate.find(text=re.compile('Mean monthly'))\n",
    "                                             .parent\n",
    "                                             .parent\n",
    "                                             .findAll('td'))\n",
    "        \n",
    "        # Annual values are listed in the last columns of the climate tables.\n",
    "        annual_sunshine_string = annual_sunshine_result_set[-1].text\n",
    "        annual_sunshine_float = float(annual_sunshine_string.replace(',',''))\n",
    "    except (AttributeError, IndexError):\n",
    "        annual_sunshine_float = float('nan')\n",
    "\n",
    "    return annual_sunshine_float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate City URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use string of letters (e.g 'ABCDEFGHI' to generate URLs to lists of towns and cities with 100,000 or more inhabitant.\n",
    "# Return urls to to lists of towns and cities with 100,000 or more inhabitant by beginning letter.\n",
    "# Function takes upercase ASCII letters.\n",
    "\n",
    "def urls_of_cities_begin_letter(letters):\n",
    "    \n",
    "    urls_of_cities = []\n",
    "    \n",
    "    for i in letters:\n",
    "        (urls_of_cities\n",
    "        .append('https://en.wikipedia.org/wiki/List_of_towns_and_cities_with_100,000_or_more_inhabitants/cityname:_'\n",
    "        + i))\n",
    "    \n",
    "    return urls_of_cities    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use URL to Wikipedia page for all cities with populations over 100,000, beginning with a certain letter.\n",
    "# Return list of URLS for each city with populations over 100,000, beginning with a certain letter.\n",
    "\n",
    "def city_urls_from_wikipedia(page_of_cities_beginning_with_letter):\n",
    "    cities_soup = web_page_to_soup(page_of_cities_beginning_with_letter)\n",
    "    \n",
    "    # Cities and URLs to their pages are listed in tables on target pages.\n",
    "    cities_table = cities_soup.find('table',{'class':'wikitable sortable'})\n",
    "    all_links = cities_table.findAll('a', href=True)\n",
    "    city_urls = []\n",
    "    \n",
    "    # Get URLs to cities; step by 2 to avoid links to city countries.\n",
    "    for i in range(0, len(all_links),2):\n",
    "        total_url = 'https://en.wikipedia.org' + all_links[i]['href']\n",
    "        city_urls.append(total_url)                 \n",
    "    \n",
    "    return city_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create List of Dictionaries with Wikipedia Data for each City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use above functions to get Wiki data for each city with population of 100,000 or more.\n",
    "## Return list of dictionaries with data for each city.\n",
    "\n",
    "def city_info_from_city_urls(city_urls_list):\n",
    "    list_of_dicts = []\n",
    "    for i in city_urls_list:\n",
    "        soup = web_page_to_soup(i)\n",
    "        city_name = city_name_from_soup(soup)\n",
    "        lat = lat_lon_from_soup(soup)[0]\n",
    "        lon = lat_lon_from_soup(soup)[1]\n",
    "        area = area_from_soup(soup)\n",
    "        elevation = elevation_from_soup(soup)\n",
    "        population = population_from_soup(soup)\n",
    "        climate = climate_from_soup(soup)\n",
    "        average_low_temp = average_low_temp_from_climate(climate)\n",
    "        average_high_temp = average_high_temp_from_climate(climate)\n",
    "        annual_precipitation_days = annual_precipitation_days_from_climate(climate)\n",
    "        annual_precipitation_inches = annual_precipitation_inches_from_climate(climate)\n",
    "        annual_sunshine_hours = annual_sunshine_hours_from_climate(climate)\n",
    "        city_dict = {\n",
    "            'City Name': city_name,\n",
    "            'URL' : i,\n",
    "            'Latitude': lat,\n",
    "            'Longitude': lon,\n",
    "            'Area': area,\n",
    "            'Elevation': elevation,\n",
    "            'Population': population,\n",
    "            'Average Low Temp': average_low_temp,\n",
    "            'Average High Temp': average_high_temp,\n",
    "            'Annual Precipitation Days': annual_precipitation_days,\n",
    "            'Annual Precipitation Inches': annual_precipitation_inches,\n",
    "            'Annual Sunshine Hours': annual_sunshine_hours,\n",
    "        }\n",
    "        list_of_dicts.append(city_dict)\n",
    "        \n",
    "    return list_of_dicts\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use above three functions to create list of Dicts for cities beginning with certain letters \n",
    "# and add them them to a DataFrame. Return dataframe with data for each city beginning with input letters.\n",
    "# Function takes upercase ASCII letters.\n",
    "\n",
    "def cities_dataframe(letters):\n",
    "    all_cities = []\n",
    "    city_letter_dataframe = pd.DataFrame()\n",
    "    \n",
    "    # Pass input letters to function to get list of URLs to city landing pages by letter.\n",
    "    urls_city_landing_pages = urls_of_cities_begin_letter(letters)\n",
    "    for i in urls_city_landing_pages:\n",
    "        \n",
    "        # Print URL to track progress.\n",
    "        print(i)\n",
    "        \n",
    "        # Pass URL to city landing pages by letter to function to get list of URLS\n",
    "        # to individual city pages.\n",
    "        city_urls_list = city_urls_from_wikipedia(i)\n",
    "        \n",
    "        # Pass list of URLS to individual city pages to function to return list of \n",
    "        # city dicts and add them to DataFrame.\n",
    "        city_letter_list_dicts = city_info_from_city_urls(city_urls_list)\n",
    "        city_letter_dataframe = pd.DataFrame(city_letter_list_dicts)\n",
    "        all_cities.append(city_letter_dataframe)\n",
    "        \n",
    "        # Pause after each iteration of the for loop to avoid rate limiting issues.\n",
    "        time.sleep(60)\n",
    "    \n",
    "    return pd.concat(all_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/wiki/List_of_towns_and_cities_with_100,000_or_more_inhabitants/cityname:_A\n",
      "https://en.wikipedia.org/wiki/List_of_towns_and_cities_with_100,000_or_more_inhabitants/cityname:_B\n",
      "https://en.wikipedia.org/wiki/List_of_towns_and_cities_with_100,000_or_more_inhabitants/cityname:_C\n",
      "https://en.wikipedia.org/wiki/List_of_towns_and_cities_with_100,000_or_more_inhabitants/cityname:_D\n",
      "https://en.wikipedia.org/wiki/List_of_towns_and_cities_with_100,000_or_more_inhabitants/cityname:_E\n",
      "https://en.wikipedia.org/wiki/List_of_towns_and_cities_with_100,000_or_more_inhabitants/cityname:_F\n",
      "https://en.wikipedia.org/wiki/List_of_towns_and_cities_with_100,000_or_more_inhabitants/cityname:_G\n",
      "https://en.wikipedia.org/wiki/List_of_towns_and_cities_with_100,000_or_more_inhabitants/cityname:_H\n",
      "https://en.wikipedia.org/wiki/List_of_towns_and_cities_with_100,000_or_more_inhabitants/cityname:_I\n"
     ]
    }
   ],
   "source": [
    "# Get city DataFrames. \n",
    "# Do this incrementally (partial alphabet) to mitigate work loss and deal with rate limiting.\n",
    "all_cities_df_a_i = cities_dataframe('ABCDEFGHI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cities_df_j_r = cities_dataframe('JKLMNOPQR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cities_df_s_z = cities_dataframe('STUVWXYZ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect DataFrames before Pickling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1313, 12)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cities_df_a_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Annual Precipitation Days</th>\n",
       "      <th>Annual Precipitation Inches</th>\n",
       "      <th>Annual Sunshine Hours</th>\n",
       "      <th>Area</th>\n",
       "      <th>Average High Temp</th>\n",
       "      <th>Average Low Temp</th>\n",
       "      <th>City Name</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Population</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130.0</td>\n",
       "      <td>39.920</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>14.61</td>\n",
       "      <td>64.0</td>\n",
       "      <td>53.2</td>\n",
       "      <td>A Coruña</td>\n",
       "      <td>190.0</td>\n",
       "      <td>43.365</td>\n",
       "      <td>-8.410</td>\n",
       "      <td>246056.0</td>\n",
       "      <td>https://en.wikipedia.org/wiki/A_Coru%C3%B1a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>32.945</td>\n",
       "      <td>1616.5</td>\n",
       "      <td>62.10</td>\n",
       "      <td>57.6</td>\n",
       "      <td>44.6</td>\n",
       "      <td>Aachen</td>\n",
       "      <td>873.0</td>\n",
       "      <td>50.783</td>\n",
       "      <td>6.083</td>\n",
       "      <td>244951.0</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Aachen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>169.3</td>\n",
       "      <td>23.626</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>39.6</td>\n",
       "      <td>Aalborg</td>\n",
       "      <td>16.0</td>\n",
       "      <td>57.050</td>\n",
       "      <td>9.917</td>\n",
       "      <td>112194.0</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Aalborg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>123.0</td>\n",
       "      <td>28.430</td>\n",
       "      <td>1506.0</td>\n",
       "      <td>35.00</td>\n",
       "      <td>52.5</td>\n",
       "      <td>38.8</td>\n",
       "      <td>Aarhus</td>\n",
       "      <td>344.0</td>\n",
       "      <td>56.150</td>\n",
       "      <td>10.217</td>\n",
       "      <td>2.0</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Aarhus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aba</td>\n",
       "      <td>673.0</td>\n",
       "      <td>5.117</td>\n",
       "      <td>7.367</td>\n",
       "      <td>534265.0</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Aba,_Nigeria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Annual Precipitation Days  Annual Precipitation Inches  \\\n",
       "0                      130.0                       39.920   \n",
       "1                        NaN                       32.945   \n",
       "2                      169.3                       23.626   \n",
       "3                      123.0                       28.430   \n",
       "4                        NaN                          NaN   \n",
       "\n",
       "   Annual Sunshine Hours   Area  Average High Temp  Average Low Temp  \\\n",
       "0                 2010.0  14.61               64.0              53.2   \n",
       "1                 1616.5  62.10               57.6              44.6   \n",
       "2                    NaN  54.00               52.0              39.6   \n",
       "3                 1506.0  35.00               52.5              38.8   \n",
       "4                    NaN  28.00                NaN               NaN   \n",
       "\n",
       "  City Name  Elevation  Latitude  Longitude  Population  \\\n",
       "0  A Coruña      190.0    43.365     -8.410    246056.0   \n",
       "1   Aachen       873.0    50.783      6.083    244951.0   \n",
       "2   Aalborg       16.0    57.050      9.917    112194.0   \n",
       "3    Aarhus      344.0    56.150     10.217         2.0   \n",
       "4       Aba      673.0     5.117      7.367    534265.0   \n",
       "\n",
       "                                           URL  \n",
       "0  https://en.wikipedia.org/wiki/A_Coru%C3%B1a  \n",
       "1         https://en.wikipedia.org/wiki/Aachen  \n",
       "2        https://en.wikipedia.org/wiki/Aalborg  \n",
       "3         https://en.wikipedia.org/wiki/Aarhus  \n",
       "4   https://en.wikipedia.org/wiki/Aba,_Nigeria  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cities_df_a_i.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annual Precipitation Days      721\n",
      "Annual Precipitation Inches    512\n",
      "Annual Sunshine Hours          841\n",
      "Area                           182\n",
      "Average High Temp              493\n",
      "Average Low Temp               493\n",
      "City Name                        0\n",
      "Elevation                      391\n",
      "Latitude                         7\n",
      "Longitude                        7\n",
      "Population                      48\n",
      "URL                              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count_nan = len(all_cities_df_a_i) - all_cities_df_a_i.count()\n",
    "print(count_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cities_df_a_i.to_pickle('all_cities_pickle_a_i.pkl')\n",
    "all_cities_df_j_r.to_pickle('all_cities_pickle_j_r.pkl')\n",
    "all_cities_df_s_z.to_pickle('all_cities_pickle_s_z.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
